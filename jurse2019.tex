\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}

\usepackage{amsmath,amssymb,amsfonts,mathrsfs}
\usepackage{algorithmic}
\usepackage{siunitx}


\usepackage{array}
\newcolumntype{x}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage{tabulary}
\usepackage{booktabs}
\usepackage{wrapfig}

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{floatrow}
\usepackage[export]{adjustbox}

\usepackage{pifont}
\newcommand{\cmark}{{\color{green} \ding{51}}}
\newcommand{\xmark}{{\color{red} \ding{55}}}

\DeclareCaptionFont{tiny}{\tiny}
\DeclareCaptionFont{scriptsize}{\scriptsize}
\captionsetup[subfigure]{labelfont={tiny, bf},textfont=tiny,singlelinecheck=on}

\usepackage{standalone}


\usepackage{textcomp}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage{xcolor}
\definecolor{darkgreen}{RGB}{0, 155, 85}

\usepackage[acronym]{glossaries}
\newacronym{acr::lod}{LoD}{Level of Detail}
\newacronym{acr::lidar}{LiDAR}{Light Detection And Ranging}
\newacronym{acr::dsm}{DSM}{Digital Surface Model}
\newacronym{acr::elod}{eLoD}{evaluation Level of Detail}

\newcounter{SubFigCounter}
\setcounter{SubFigCounter}{1}

\begin{document}

\title{The necessary yet complex evaluation of 3D city models: a semantic approach}

\author{\IEEEauthorblockN{Oussama Ennafii, Cl\'ement Mallet, Arnaud Le Bris}
\IEEEauthorblockA{Univ. Paris Est, IGN-ENSG, LaSTIG, Saint-Mand\'e, France \\
firstname.lastname@ign.fr}
\and
\IEEEauthorblockN{Florent Lafarge}
\IEEEauthorblockA{Inria, TITANE, Sophia Antipolis, France\\
florent.lafarge@inria.fr}
}

\maketitle

\IEEEpubid{
    \begin{minipage}{\textwidth}\ \\[12pt] \centering
        ~ \\~ \\~\\ 
        978-1-7281-0009-8/19/\$31.00 \copyright 2019 IEEE
    \end{minipage}
}

\begin{abstract}
	The automatic modeling of urban scenes in 3D from geospatial data has been studied for more than thirty years. However, the output models still have to undergo a tedious task of correction at city scale. In this work, we propose an approach for automatically evaluating the quality of 3D building models. A taxonomy of potential errors is first proposed. Handcrafted features are computed, based on the geometric properties of buildings and, when available, Very High Resolution images and depth data. They are fed into a Random Forest classifier for the prediction of the quality of the models. We tested our framework on three distinct urban areas in France. We can satisfactorily detect, on average 96\% of the most frequent errors.
\end{abstract}
\begin{IEEEkeywords}
  3D, modeling, buildings, quality, taxonomy, classification, error detection, geometry, VHR data.
\end{IEEEkeywords}

\section{Introduction}

	Although automatic 3D urban modeling has been extensively studied for many years by academics and industrials alike, current algorithms fail to adapt to different urban settings~\cite{Musialski2012}. Output building models still have to be inspected by human operators for quality assessment and subsequent correction. Thus, scalability is not handled in the literature albeit being critical in operational contexts. In this work, we study the automation of 3D building model evaluation. We focus on assessing polyhedral structured models. They represent building roof architectures, which result from a given urban reconstruction method, unknown here. Each facet of the model corresponds to an architectural (post of the time planar) feature. Such 3D models do not correspond to triangle meshes. The latter ones exhibit higher data fidelity but lower compacity and no semantics. Depending on the spatial resolution of input data, the urban scene, and the intended use, the reconstituted model has a certain \textbf{\gls{acr::lod}}~\cite{kolbe2005citygml}.
    
    Few works have addressed the quality assessment of 3D urban models at building level. Usually, visual inspection~\cite{Durupt2006} or comparison with field measurements~\cite{Kaartinen2005} are performed, void of structural information. Our work focuses on semantically evaluating the structural compliance of modeled buildings. We define an evaluation framework that can be used for building model correction, change detection, reconstruction method selection, and crowdsourcing evaluation. We ignore format/geometric issues~\cite{ledoux2018val3dity}. Our framework targets to be independent from the \acrlong{acr::lod} and the modeling method. Quality metrics can be provided with the reconstruction process but lack of independence with the underlying method. 

	\begin{figure}
        \begin{center}
            \includestandalone[mode=buildnew, width=\textwidth]{graphical_abstract}
            \vspace{-1.3cm}
            \caption{\label{fig::pipeline} The semantic evaluation paradigm proposal. Geometric structural features are first proposed (b), potentially augmented with attributes based on height map and color gradient comparison (c-d). Semantic errors are eventually predicted using a pretrained classifier.}
        \end{center}
    \end{figure}

     This work proposes an adaptable and flexible framework. It is indifferent to input urban scenes and reconstruction methods (Figure~\ref{fig::pipeline}). For that purpose, our contributions are three-fold:
    \begin{itemize}
        \item A new \textbf{taxonomy of errors}, hierarchical, adapted to all \acrshort{acr::lod}, and independent from input models;
        \item A \textbf{supervised classification} formulation of the problem, which predicts all errors affecting the building model;
        \item A multimodal \textbf{baseline of features}, which are extracted both from the model and external data (Very High Resolution optical images and height data).
    \end{itemize}

Section~\ref{sec:related} introduces the problem of the evaluation of 3D building models and discusses existing methods. Section~\ref{sec:approach} details the proposed approach, while data and results of experiments conducted over three urban areas are presented in Section~\ref{sec:expe}. Main conclusions are drawn in Section~\ref{sec::conclusion}.

\section{Related Work}
\label{sec:related}
	3D urban models qualification has been barely investigated in the literature despite plethora of modeling approaches. Methods can be classified based on the assessment criteria: geometric fidelity indices or semantic errors. Geometric fidelity metrics quantify the modeling accuracy relying on the precision of points of interest (e.g., intersection points), of surfaces or on the 3D model volume. These are usually compared to higher resolution reference data~\cite{Kaartinen2005,Zeng2014}. These metrics fail to describe local modeling defects. Consequently, semantic errors are preferred for such a task, often following the traffic light paradigm. For instance, four levels of quality are defined in~\cite{boudet2006supervised}: Correct, Acceptable, Generalized, and False. However, these levels are not explicitly quantified and are ill defined: they depends on the end-user. The error taxonomy can also adopt the modeling method perspective. Errors can be grouped into footprint ones (e.g., erroneous outline, missing inner court) and modeling errors (under/over-segmentation, height inaccuracy). These are therefore method-dependent. The building model is therefore assessed owing to a supervised classification that takes these defined errors as labels. In order to represent input models, features are extracted from aerial images or \acrfull{acr::dsm} at very high resolution (\SIrange{20}{25}{\cm}), by 3D segments comparisons or texture correlation ratios~\cite{Michelin2013,boudet2006supervised}. Despite satisfactory results, this approach exhibits two main drawbacks: a taxonomy specific to some urban scenes or modeling methods and a complex feature computation step, preventing upscaling strategies. The main idea of our work is to propose an agnostic assessment approach that do not rely on reference data and complex features.

\section{Methodology}
\label{sec:approach}

Our method relies on predicting errors in order to qualify a 3D model at the scale of a building. Errors are defined in a hierarchical taxonomy, based on the assessment objectives. Handcrafted features of various kinds are computed (Figure~\ref{fig::pipeline}). A supervised classifier is trained using annotated building models and tested later on unseen buildings for quality prediction based on the detected errors. This pipeline is modular: it takes into account geometric features, coming from the 3D model, which can be augmented by height features, from the \acrshort{acr::dsm}, or optical features, from a VHR orthoimage.

\subsection{Error taxonomy}
	Two criteria are taken into account so as to build a generic and flexible taxonomy (Figure~\ref{fig::taxonomy}): the \acrshort{acr::lod} and the semantic level, which we call henceforth \textit{finesse}. An \textit{atomic} error is one with maximal \textit{finesse}: it corresponds, intuitively, to a unitary action that an operator should take in order to correct a model.
    
    From an operational perspective, not all buildings are qualifiable. For instance, buildings can be occluded by vegetation or happen to show self-intersection problems. These pathological cases are outside the realm of our assessment framework. Thus, in the \textit{finesse} level equal to $0$, we discriminate between \textit{Qualifiable} and \textit{Unqualifiable} models. At the next level, models are classified being \textit{Valid} or \textit{Erroneous}. Based on the \acrshort{acr::lod}, these last models are distinguished into error families at \textit{finesse} equal to $2$. \textit{Building errors} correspond to defects at the building level (\acrshort{acr::lod}-1 $\cup$ \acrshort{acr::lod}-0). Errors related to building facets (\acrshort{acr::lod}-2) are assembled into \textit{Facet errors}. The last family, \textit{Superstructure errors}, groups errors pertaining to \acrshort{acr::lod}-3 errors. These families contain \textit{atomic} errors that have a maximal \textit{finesse} equal to $3$.
    
    This error arrangement does not depend on a particular modeling method or urban environment. Labels are not redundant as \textit{atomic} errors are chosen to be independent from each other. They represent a particular topological or geometric defect. Topological errors relate to structural defects in the model, while geometrical ones address modeling imprecision. 
    
    We propose the following \textit{atomic} errors based on our comprehensive analysis on overhead aerial models.\\
	\begin{figure}
        \begin{center}
            \includestandalone[mode=buildnew, width=\textwidth]{taxonomy_tree}
            \vspace{-1.1cm}
            \caption{\label{fig::taxonomy} The proposed taxonomy structure. In the VHR overhead case, only two families of errors are depicted. At \textit{finesse} level $2$, a hierarchy exists and \textbf{exclusivity} may prevail.}
        \end{center}
    \end{figure}
- \textbf{Building errors} family (Figure~\ref{fig::bul_err}):
        \begin{itemize}
        	\item \textit{Under segmentation} (\textit{BUS}): two or more buildings are modeled as one;
            \item \textit{Over segmentation} (\textit{BOS}): one building is subdivided into two or more buildings;
            \item \textit{Imprecise footprint borders} (\textit{BImB}): the building footprint borders are imprecise;
            \item \textit{Inaccurate footprint topology} (\textit{BInT}): the building footprint suffers from topological defects as missing inner courts or wrong primitive fitting;
            \item \textit{Imprecise geometry} (\textit{BIG}): inaccurate building geometric estimation. In case \textbf{\acrshort{acr::elod}} $>$ \acrshort{acr::lod}-0 $\cup$ \acrshort{acr::lod}-1, this error is not reported (redundant with errors below);
        \end{itemize}
- \textbf{Facet errors} family (Figure~\ref{fig::fac_err}):
        \begin{itemize}
        	\item \textit{Under segmentation} (\textit{FUS}): two or more facets are modeled as one;
            \item \textit{Over segmentation} (\textit{FOS}): one facet is subdivided into two or more facets;
            \item \textit{Imprecise borders} (\textit{FIB}): the facet borders are imprecise;
            \item \textit{Inaccurate topology} (\textit{FIT}): the facet suffers from topological defects like a wrong primitive fitting;
            \item \textit{Imprecise geometry} (\textit{FIG}): inaccurate facet geometric estimation.
        \end{itemize}

    
    \begin{figure*}
        \begin{center}
            \ffigbox{
                \ffigbox[\FBwidth]
                {
                    \begin{subfloatrow}[4]
                        \ffigbox[\FBwidth]{\caption{\textit{BUS}}\label{fig::under_bul}}{\includegraphics[height=.11\textheight]{images/Building_Errors/under_segmentation}}
                        \ffigbox[\FBwidth]{\caption{\textit{BOS}}\label{fig::over_bul}}{\includegraphics[height=.11\textheight]{images/Building_Errors/over_segmentation}}
                        \ffigbox[\FBwidth]{\caption{\textit{BImB}}\label{fig::footprint}}{\includegraphics[height=.11\textheight]{images/Building_Errors/footprint}}
                        \ffigbox[\FBwidth]{\caption{\textit{BInT}}\label{fig::height}}{\includegraphics[height=.11\textheight]{images/Building_Errors/topology}}
                    \end{subfloatrow}
                }
                {
                    \captionsetup{labelfont={tiny, bf},textfont=scriptsize,justification=raggedright, labelsep=period}
                    \renewcommand{\thesubfigure}{\roman{SubFigCounter}}
					\vspace{-.3cm}
                    \captionof{subfigure}{Building errors family samples.}\label{fig::bul_err}
                    \refstepcounter{SubFigCounter}
                    \addtocounter{figure}{-1}
                }
                \ffigbox[\FBwidth]
                {
                    \begin{subfloatrow}[5]
                        \ffigbox[\FBwidth]{\caption{\textit{FUS}}\label{fig::under_fac}}{\includegraphics[height=.11\textheight]{images/Facet_Errors/under_segmentation}}
                        \ffigbox[\FBwidth]{\caption{\textit{FOS}}\label{fig::over_fac}}{\includegraphics[height=.11\textheight]{images/Facet_Errors/over_segmentation}}
                        \ffigbox[\FBwidth]{\caption{\textit{FIB}}\label{fig::mis}}{\includegraphics[height=.11\textheight]{images/Facet_Errors/mis_segmentation}}
                        \ffigbox[\FBwidth]{\caption{\textit{FIT}}\label{fig::topology}}{\includegraphics[height=.11\textheight]{images/Facet_Errors/topology}}
                        \ffigbox[\FBwidth]{\caption{\textit{FIG}}\label{fig::slope}}{\includegraphics[height=.11\textheight]{images/Facet_Errors/slope}}
                    \end{subfloatrow}
                }
                {
                	\captionsetup{labelfont={bf},justification=raggedright, labelsep=period}
                    \renewcommand{\thesubfigure}{\roman{SubFigCounter}}
					\vspace{-.3cm}
                    \captionof{subfigure}{Facet errors family samples.}\label{fig::fac_err}
                    \refstepcounter{SubFigCounter}
                    \addtocounter{figure}{-1}
                }
            }
            {
            	\vspace{-.4cm}
                \caption{\label{fig::samples}Illustration of various errors of our taxonomy. One can see that geometric, spectral and height information are required for an accurate detection of all kinds of errors.}
            }
        \end{center}
    \end{figure*}

\subsection{Feature baseline}

	We propose a simple handcrafted set. We limit ourself to the validation of the semantic approach and taxonomy validation. We rely on three modalities. The first is the input 3D model. We extract statistics (maximum, minimum, mean, median and standard deviation) over attributes that describe the geometry of the building facets: number of nodes, area, angle between normals, distance between centroids and circumference. We add height attributes. These are represented by the histogram of the discrepancy between the rasterized model height map and the \acrshort{acr::dsm} at the same spatial resolution. It is chosen to be lower than building dimensions but higher than the modeling inherent planimetric uncertainty. Last comes optical features, computed by back-projecting the model on corresponding VHR orthoimage. For each facet edge, we compute a correlation histogram to image edges (cosine similarity between local gradients and the edge normal). This histogram is summed over all facet edges and then over all projected facets. Histograms concentrated near the value $1$ means facet edges correspond to genuine ones in the VHR image. Each modality provides 20 features.

\subsection{Classification process}

The labels are organized into different classification problems. To account for the desired modularity and flexibility, a random forest classifier is chosen (1,000 trees, maximal depth of 4). The depth is kept shallow in order to avoid overfitting while the large number of estimators deals with the large feature space variability. The \textit{Multi-label} setting is managed using a One vs All strategy on top of our classifier.

\section{Experiments}
\label{sec:expe}

\begin{wraptable}{r}{5cm}
	\begin{center}
		\scriptsize
        \begin{tabular}{x{1cm} x{.5cm} x{.5cm} x{.5cm}}
            \toprule
            & \rotatebox{90}{\textbf{Elancourt}} & \rotatebox{90}{\textbf{Nantes}} & \rotatebox{90}{\textbf{Paris-13}} \\
            \midrule
            \# samples & 2009 & 748 & 478 \\
            \acrshort{acr::dsm} res. & \SI{6}{\cm} & \SI{10}{\cm} & \SI{10}{\cm} \\
            Img. res. & \SI{6}{\cm} & \SI{10}{\cm} & \SI{10}{\cm} \\
            \bottomrule
        \end{tabular}
        \vspace{-.5cm}
        \caption{\label{tab::dataset} Dataset details.}
	\end{center}
\end{wraptable}

We evaluate our approach on a dataset drawn from three French cities: Elancourt, Nantes and one district of Paris (Paris-13). Elancourt exhibits a high diversity of building types: residential areas (bi-level buildings) and industrial sections (flat roofs). Nantes represents a denser urban setting with lower diversity. In Paris-13, high towers coexist with Haussmann style buildings. Input 3D models were obtained using the algorithm described in~\cite{Durupt2006}, out of existing footprints and an aerial VHR multi-view \acrshort{acr::dsm}. They were annotated according to the atomic errors list provided by our taxonomy. More details are reported in Table~\ref{tab::dataset}.

Labels are extracted from the taxonomy at \textit{finesse} level of $3$. In Table~\ref{tab::ablation}, we report results over Elancourt using all four possible feature configurations performing a 10-fold cross validation. In Table~\ref{tab::transferability}, we experimented training over buildings from one urban zone and testing on another.

\begin{table*}
	\scriptsize
	\begin{center}
        \begin{tabular}{|x{1.4cm} | x{1.2cm} x{1.2cm} | x{1.2cm} x{1.2cm} | x{1.2cm} x{1.2cm} | x{1.2cm} x{1.2cm}|}
			\hline
            &\multicolumn{2}{x{2.4cm}|}{\textbf{Geometry}} & \multicolumn{2}{x{2.4cm}|}{\textbf{Geom. $\cup$ Height}} & \multicolumn{2}{x{2.4cm}|}{\textbf{Geom. $\cup$ Image}} & \multicolumn{2}{|x{2.4cm}|}{\textbf{All}}\\
            \cline{2-9}
            &\textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.}\\
            \hline
            \textit{BOS} & \textbf{93.96} & 76.15 & 91.43 & \textbf{77.76} & 91.51 & 76.08 & 90.83 & 76.14 \\
            \hline
            \textit{BUS} & 32.98 & \textbf{76.47} & \textbf{41.86} & 75.57 & 40.38 & 71.00 & 39.32 & 71.81 \\
            \hline
            \textit{BImB} & 12.32 & 67.57 & 12.81 & \textbf{68.42} & 16.26 & 67.35 & \textbf{16.75} & 68.0 \\
            \hline
            \textit{BInT} & \textbf{25.25} & 92.59 & 20.20 & 90.91 & 20.20 & \textbf{95.24} & 11.11 & 91.67 \\
            \hline
            \hline
            \textit{FOS} & 98.91 & 99.07 & 98.91 & \textbf{99.30} & \textbf{98.99} & 98.84 & 98.91 & 98.84 \\
            \hline
            \textit{FUS} & \textbf{1.90} & 54.55 & 0.63 & \textbf{66.67} & 1.61 & 50 & 1.27 & \textbf{66.67} \\
            \hline
            \textit{FIB} & \textbf{9.17} & 87.5 & 0 & --- & 8.30 & 82.61 & 7.42 & \textbf{100} \\
            \hline
            \textit{FIT} & \textbf{6.67} & \textbf{100} & 8.73 & 95.24 & 3.33 & \textbf{100} & 3.33 & \textbf{100} \\
            \hline
            \textit{FIG} & \textbf{80.54} & 73.14 & 80.45 & \textbf{72.62} & 78.69 & 72.12 & 79.02 & 71.82 \\
            \hline
		\end{tabular}
	\end{center}
    \vspace{-.5cm}
    \caption{\label{tab::ablation}Ablation study (in \%) at \textit{finesse} $= 3$ on Elancourt.}
\end{table*}

\begin{table*}
	\begin{center}
    	\scriptsize
		\begin{tabular}{|x{1cm} | x{1.2cm} x{1.2cm} | x{1.2cm} x{1.2cm} || x{1.2cm} x{1.2cm}| x{1.2cm} x{1.2cm}|}
            \hline
            & \multicolumn{2}{x{2.4cm}|}{\textbf{Elancourt $\rightarrow$ Nantes}} & \multicolumn{2}{x{2.4cm}||}{\textbf{Elancourt $\rightarrow$ Paris-13}} & \multicolumn{2}{x{2.4cm}|}{\textbf{Nantes $\rightarrow$ Elancourt}} & \multicolumn{2}{x{2.4cm}|}{\textbf{Paris-13 $\rightarrow$ Elancourt}}\\
            \cline{2-9}
            &\textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} \\
            \hline
            \textit{BOS} & \textcolor{darkgreen}{100} & \textcolor{red}{42.05} & \textcolor{red}{78.71} & \textcolor{red}{42.97} & \textcolor{orange}{86.47} & \textcolor{orange}{64.99} & \textcolor{orange}{82.14} & \textcolor{orange}{69.59} \\
            \hline
            \textit{BUS} & \textcolor{red}{19.12} & \textcolor{red}{54.17} & \textcolor{red}{4.76} & \textcolor{red}{27.27} & \textcolor{red}{23.75} & \textcolor{red}{57.47} & \textcolor{red}{25.0} & \textcolor{red}{50.49} \\
            \hline
            \textit{BImB} & \textcolor{red}{0} & \textcolor{red}{---} & \textcolor{red}{1.85} & \textcolor{red}{33.33} & \textcolor{darkgreen}{15.65} & \textcolor{red}{46.75} & \textcolor{darkgreen}{19.89} & \textcolor{red}{48.05} \\
            \hline
            \textit{BInT} & \textcolor{darkgreen}{40.71} & \textcolor{red}{14.24} & \textcolor{red}{0} & \textcolor{red}{---}  & \textcolor{red}{4.70} & 100 & \textcolor{red}{4.44} & 100 \\
            \hline
            \hline
            \textit{FOS} & \textcolor{darkgreen}{100} & \textcolor{red}{69.38} & \textcolor{darkgreen}{98.80} & \textcolor{orange}{96.47} & \textcolor{darkgreen}{98.76} & \textcolor{darkgreen}{98.92} & \textcolor{darkgreen}{99.06} & \textcolor{darkgreen}{97.14} \\
            \hline
            \textit{FUS} & \textcolor{darkgreen}{15.71} & \textcolor{orange}{56.90} & \textcolor{darkgreen}{20.73} & \textcolor{darkgreen}{91.94} & 1.68 & 77.78 & 3.53 & 89.47 \\
            \hline
            \textit{FIB} & \textcolor{darkgreen}{83.54} & \textcolor{red}{43.08} & \textcolor{darkgreen}{39.58} & \textcolor{red}{64.04} & \textcolor{darkgreen}{23.75} & 73.96 & \textcolor{darkgreen}{21.86} & 70.11 \\
            \hline
            \textit{FIT} & 9.09 & 33.33 & 0 & 0 & 3.57 & 100 & 4.34 & 33.33 \\
            \hline
            \textit{FIG} & \textcolor{darkgreen}{100} & \textcolor{orange}{64.45} & \textcolor{darkgreen}{90.86} & \textcolor{darkgreen}{86.14} & \textcolor{darkgreen}{86.35} & \textcolor{orange}{67.97} & \textcolor{darkgreen}{82.38} & \textcolor{darkgreen}{73.08} \\
            \hline
        \end{tabular}
        \vspace{-.5cm}
        \caption{\label{tab::transferability} Transferability study (in \%) at \textit{finesse} $= 3$ over different urban scenes using all features. Compared to previous results in Table~\ref{tab::ablation}, \textcolor{darkgreen}{$\blacksquare$}: a stable or better result, \textcolor{orange}{$\blacksquare$}: a small drop and \textcolor{red}{$\blacksquare$}: a significant decrease in accuracy.}
	\end{center}
\end{table*}
\begin{figure*}
	\begin{center}
    \tiny
		\begin{tabular}{| x{1.11cm} | x{.75cm} | x{.75cm} || x{1.11cm} | x{.75cm} | x{.75cm} || x{1.11cm} | x{.75cm} | x{.75cm} || x{1.11cm} | x{.75cm} | x{.75cm} |}
			\hline
			\multicolumn{3}{| c ||}{\includegraphics[height=.1\textheight,valign=m,margin=.1cm .1cm]{images/prediction_results/valid_as_bul_over}} & \multicolumn{3}{ c ||}{\includegraphics[height=.1\textheight,valign=m,margin=0cm .1cm]{images/prediction_results/no_imprec_no_fac_over}} & \multicolumn{3}{ c ||}{\includegraphics[height=.1\textheight,valign=m,margin=0cm .1cm]{images/prediction_results/no_under_seg}} & \multicolumn{3}{ c |}{\includegraphics[height=.1\textheight,valign=m,margin=0cm .1cm]{images/prediction_results/no_bul_under_seg}} \\
			\hline
			\textbf{Errors} & \textbf{G.T.} & \textbf{Pred.} & \textbf{Errors} & \textbf{G.T.} & \textbf{Pred.} & \textbf{Errors} & \textbf{G.T.} & \textbf{Pred.} & \textbf{Errors} & \textbf{G.T.} & \textbf{Pred.}\\
            \hline
            \textit{BOS} & \xmark & \cmark & \textit{BUS} & \xmark & \cmark & \textit{BOS} & \cmark & \cmark & \textit{BOS} & \cmark & \xmark \\
            Valid & \cmark & \xmark & \textit{FIG} & \cmark & \xmark & \textit{FUS} & \cmark & \xmark &  \textit{FOS} & \cmark & \xmark \\
             &  &  & \textit{FOS} & \cmark & \xmark &  &  &  & \textit{BUS} & \cmark & \xmark \\
             &  &  &  &  &  &  &  &  &  \textit{BImB} & \cmark & \cmark \\
            \hline
		\end{tabular}
        \vspace{-.5cm}
        \caption{\label{fig::results} Predicted (Pred.) errors compared to ground truth (G.T.) labels are illustrated in some pathological cases. Knowing how each error is represented in the dataset helps interpreting misclassifications.}
	\end{center}
\end{figure*}

From Table~\ref{tab::ablation}, we can see that well represented errors are correctly detected. In fact, \textit{BOS} (\textit{resp.} \textit{FOS}, \textit{FIB}), with a $66.8\%$ (\textit{resp.} $64.16\%$, $59.08\%$) occurrence ratio, attains, in average across all configurations, a high recall ratio of $91.93\%$ (\textit{resp.} $98.93\%$, $79,68\%$). In contrast, other \textit{atomic} errors which are not frequently found in the dataset (a$\sim$$10\%$ of the total) are naturally harder to detect. The ablation study reveals that, for most errors, geometric features yield sensibly the same results, except for \textit{BUS} (where height and/or image based features add around $10\%$ in recall while loosing at most $5\%$ in precision), and for \textit{BImB} (as image based features add around $4\%$ in recall without a loss in precision). In Paris-13 and Nantes buildings are often more adjacent than Elancourt, this perfectly explains why classifiers trained over Paris/Nantes are better, regarding Building \textit{atomic} errors, in recall and precision than the ones trained over Elancourt and tested on them. It achieves even close or better recall ratio over \textit{BimB} if compared to classifiers trained on Elancourt itself. However, Facet \textit{atomic} errors are much more easily detected if the classifiers are trained over Elancourt and tested on the other cities. It is also mostly stable compared to evaluation on Elancourt itself and even yields much better results for \textit{FIB} and \textit{FIG}. This can be explained by the fact that Haussmann style buildings and high flat towers offer less diverse facet geometries compared to bi-level hipped roofs, industrial buildings and other residential features that are present in the Elancourt scene.

Qualitative assessment is also performed in order to illustrate some failure cases. In the leftmost example of Figure~\ref{fig::results}, the similarity of the building outline to over segmented buildings cases induces an overdetection. Sometimes, the VHR of the data does not suffice to detect all errors that are visually identifiable. In general, these samples help us devise more robust features so as to alleviate these issues. Dataset enrichment could be another option which provides more instances of underrepresented errors. In the end, we can also add the human in the loop through a manual interactive evaluation/classification mechanism which could adapt well to user-specific needs.



\section{Conclusion}
\label{sec::conclusion}

We proposed a framework to semantically evaluate 3D building models. Errors were hierarchically organized into a flexible and parametrizable taxonomy, handling the large diversity of urban environments and end users' requirements. Model quality was predicted using a supervised classifier using three modalities. Although being mitigated over under-represented errors, results are satisfactory in the well balanced cases. As a next step, more structurally aware features (e.g., based on graph comparison) will be proposed, so as to be applied on a richer and more diverse dataset (potentially involving data augmentation) under a deep-based framework.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,references}
\end{document}

